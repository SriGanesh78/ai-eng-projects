{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "568f5f07",
   "metadata": {},
   "source": [
    "# Project 2: Customer‑Support Chatbot for an E-Commerce Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe2a04",
   "metadata": {},
   "source": [
    "Welcome! In this project, you'll build a **chatbot** that answers customer service questions about Everstorm Outfitters, an imaginary e-commerce store.\n",
    "\n",
    "Run each cell in order. Feel free to modify them as you go to better understand each tool and search the web or look online for documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e17b2",
   "metadata": {},
   "source": [
    "## Learning Objectives  \n",
    "* **Ingest & chunk** unstructured docs  \n",
    "* **Embed** chunks and **index** with *FAISS*  \n",
    "* **Retrieve** context and **craft prompts**  \n",
    "* **Run** an open‑weight LLM locally with *Ollama*  \n",
    "* **Build** a Retrieval-Augmented Generation (RAG) chain\n",
    "* **Package** the chat loop in a minimal **Streamlit** web UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46b9cc",
   "metadata": {},
   "source": [
    "## Roadmap  \n",
    "We will build a RAG-based chatbot in **six** steps:\n",
    "\n",
    "1. **Environment setup**\n",
    "2. **Data preparation**  \n",
    "   a. Load source documents  \n",
    "   b. Chunk the text  \n",
    "3. **Build a retriever**  \n",
    "   a. Generate embeddings  \n",
    "   b. Build a FAISS vector index  \n",
    "4. **Build a generation engine**. Load the *Gemma3-1B* model through Ollama and run a sanity check.  \n",
    "5. **Build a RAG**. Connect the system prompt, retriever, and LLM together. \n",
    "6. **(Optional) Streamlit UI**. Wrap everything in a simple web app so users can chat with the bot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a01819c",
   "metadata": {},
   "source": [
    "## 1 - Environment setup\n",
    "\n",
    "We use conda to manage our project dependencies and ensure everyone has a consistent setup. Conda is an open-source package and environment manager that makes it easy to install libraries and switch between isolated environments. To learn more about conda, you can read: https://docs.conda.io/en/latest/\n",
    "\n",
    "Create and activate a clean *conda* environment and install the required packages. If you don't have conda installed, visit https://www.anaconda.com/docs/getting-started/miniconda/main.\n",
    "\n",
    "\n",
    "Open your terminal, navigate to the project folder where this notebook is located, and run the following commands.\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml && conda activate rag-chatbot\n",
    "\n",
    "# (Optional but recommended) Register this environment as a Jupyter kernel\n",
    "python -m ipykernel install --user --name=rag-chatbot --display-name \"rag-chatbot\"\n",
    "```\n",
    "Once this is done, you can select “rag-chatbot” from the Kernel → Change Kernel menu in Jupyter or VS Code.\n",
    "\n",
    "\n",
    "> Behind the scenes:\n",
    "> * Conda reads `environment.yml`, solves all pinned dependencies, and builds an isolated environment named `rag-chatbot`.\n",
    "> * When it reaches the file’s \"pip:\" section, Conda automatically invokes pip to install any remaining Python-only packages so the whole stack be available for the project.\n",
    "> * Registering the kernel makes your new environment visible to Jupyter, so the notebook runs inside the same environment you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa9ee989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-1.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain) (1.0.0)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.8)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading ormsgpack-1.11.0-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.1)\n",
      "Downloading langchain-1.0.0-py3-none-any.whl (106 kB)\n",
      "Downloading langgraph-1.0.0-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n",
      "Downloading langgraph_prebuilt-1.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading ormsgpack-1.11.0-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (368 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [langchain]/7\u001b[0m [langgraph]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-1.0.0 langgraph-1.0.0 langgraph-checkpoint-2.1.2 langgraph-prebuilt-1.0.0 langgraph-sdk-0.2.9 ormsgpack-1.11.0 xxhash-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee6b61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (0.4)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (0.4.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (2.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: langchain-openai in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (0.3.28)\n",
      "Collecting langchain-core<1.0.0,>=0.3.68 (from langchain-openai)\n",
      "  Using cached langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-openai) (1.97.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.14.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Using cached langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
      "Installing collected packages: langchain-core\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.0.0\n",
      "    Uninstalling langchain-core-1.0.0:\n",
      "      Successfully uninstalled langchain-core-1.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-text-splitters 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-ollama 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-community 0.4 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-huggingface 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.79\n",
      "Requirement already satisfied: langchain-ollama in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (1.0.0)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain-ollama)\n",
      "  Using cached langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-ollama) (0.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.4.8)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.11.7)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.3.1)\n",
      "Using cached langchain_core-1.0.0-py3-none-any.whl (467 kB)\n",
      "Installing collected packages: langchain-core\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.79\n",
      "    Uninstalling langchain-core-0.3.79:\n",
      "      Successfully uninstalled langchain-core-0.3.79\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.3.28 requires langchain-core<1.0.0,>=0.3.68, but you have langchain-core 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-1.0.0\n",
      "Requirement already satisfied: langchain-huggingface in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (1.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-huggingface) (0.35.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: filelock in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.1.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (2.11.7)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-huggingface) (1.3.1)\n",
      "Requirement already satisfied: langchain-community in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (0.4)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (0.4.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-community) (2.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: langchain-openai in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (0.3.28)\n",
      "Collecting langchain-core<1.0.0,>=0.3.68 (from langchain-openai)\n",
      "  Using cached langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-openai) (1.97.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.14.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Using cached langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
      "Installing collected packages: langchain-core\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.0.0\n",
      "    Uninstalling langchain-core-1.0.0:\n",
      "      Successfully uninstalled langchain-core-1.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-text-splitters 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-ollama 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-community 0.4 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-huggingface 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.79\n",
      "Requirement already satisfied: langchain-ollama in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (1.0.0)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain-ollama)\n",
      "  Using cached langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-ollama) (0.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.4.8)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.11.7)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.3.1)\n",
      "Using cached langchain_core-1.0.0-py3-none-any.whl (467 kB)\n",
      "Installing collected packages: langchain-core\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.79\n",
      "    Uninstalling langchain-core-0.3.79:\n",
      "      Successfully uninstalled langchain-core-0.3.79\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.3.28 requires langchain-core<1.0.0,>=0.3.68, but you have langchain-core 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community\n",
    "!pip install langchain-openai\n",
    "!pip install langchain-ollama\n",
    "!pip install langchain-huggingface\n",
    "!pip install langchain-community\n",
    "!pip install langchain-openai\n",
    "!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a29e43",
   "metadata": {},
   "source": [
    "Let's import required libraries and print a message if we're not **missing packages**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b49fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported! You're good to go!\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries for file handling and text processing\n",
    "import os, pathlib, textwrap, glob\n",
    "\n",
    "# Load documents from various sources (URLs, text files, PDFs)\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader, TextLoader, PyPDFLoader\n",
    "\n",
    "# Split long texts into smaller, manageable chunks for embedding\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Vector store to store and retrieve embeddings efficiently using FAISS\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Generate text embeddings using OpenAI or Hugging Face models\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "# Use local LLMs (e.g., via Ollama) for response generation\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Build a retrieval chain that combines a retriever, a prompt, and an LLM\n",
    "# Note: We'll use RetrievalQA chain from langchain_classic\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "# Create prompts for the RAG system\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "print(\"✅ Libraries imported! You're good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "230e5b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "Ignoring wrong pointing object 76 0 (offset 0)\n",
      "Ignoring wrong pointing object 80 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 PDF files:\n",
      "  - data/Everstorm_Return_and_exchange_policy.pdf\n",
      "  - data/Everstorm_Return_and_exchange_policy 2.pdf\n",
      "  - data/Everstorm_Product_sizing_and_care_guide.pdf\n",
      "  - data/Everstorm_Shipping_and_Delivery_Policy 2.pdf\n",
      "  - data/Everstorm_Product_sizing_and_care_guide 2.pdf\n",
      "  - data/Everstorm_Shipping_and_Delivery_Policy.pdf\n",
      "  - data/Everstorm_Payment_refund_and_security.pdf\n",
      "  - data/Everstorm_Payment_refund_and_security 2.pdf\n",
      "\n",
      "Loading data/Everstorm_Return_and_exchange_policy.pdf...\n",
      "  ✓ Loaded 2 pages\n",
      "\n",
      "Loading data/Everstorm_Return_and_exchange_policy 2.pdf...\n",
      "  ✗ Error loading data/Everstorm_Return_and_exchange_policy 2.pdf: Cannot read an empty file\n",
      "\n",
      "Loading data/Everstorm_Product_sizing_and_care_guide.pdf...\n",
      "  ✓ Loaded 2 pages\n",
      "\n",
      "Loading data/Everstorm_Shipping_and_Delivery_Policy 2.pdf...\n",
      "  ✗ Error loading data/Everstorm_Shipping_and_Delivery_Policy 2.pdf: Cannot read an empty file\n",
      "\n",
      "Loading data/Everstorm_Product_sizing_and_care_guide 2.pdf...\n",
      "  ✗ Error loading data/Everstorm_Product_sizing_and_care_guide 2.pdf: Cannot read an empty file\n",
      "\n",
      "Loading data/Everstorm_Shipping_and_Delivery_Policy.pdf...\n",
      "  ✓ Loaded 2 pages\n",
      "\n",
      "Loading data/Everstorm_Payment_refund_and_security.pdf...\n",
      "  ✓ Loaded 2 pages\n",
      "\n",
      "Loading data/Everstorm_Payment_refund_and_security 2.pdf...\n",
      "  ✗ Error loading data/Everstorm_Payment_refund_and_security 2.pdf: Cannot read an empty file\n",
      "\n",
      "📚 Total documents loaded: 8 pages\n",
      "📄 Sample document metadata:\n",
      "  - Source: data/Everstorm_Return_and_exchange_policy.pdf\n",
      "  - Page: 0\n",
      "  - Content preview: Everstorm  Outfitters    RETURN  &  EXCHANGE  POLICY    Document  ROX-2025-05   Easy-Fit  Promise    If  your  gear  doesn’t  fit  or  just  isn’t  your  vibe,  send  it  back  within  **30  days**  o...\n"
     ]
    }
   ],
   "source": [
    "# Load all Everstorm PDF files using PyPDFLoader\n",
    "import glob\n",
    "\n",
    "# Find all PDF files matching the pattern\n",
    "pdf_files = glob.glob(\"data/Everstorm_*.pdf\")\n",
    "print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "for pdf_file in pdf_files:\n",
    "    print(f\"  - {pdf_file}\")\n",
    "\n",
    "# Load all PDFs and collect pages in raw_docs\n",
    "raw_docs = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    print(f\"\\nLoading {pdf_file}...\")\n",
    "    try:\n",
    "        # Create PyPDFLoader instance for this PDF\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        # Load all pages from the PDF\n",
    "        pages = loader.load()\n",
    "        raw_docs.extend(pages)\n",
    "        print(f\"  ✓ Loaded {len(pages)} pages\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error loading {pdf_file}: {e}\")\n",
    "\n",
    "print(f\"\\n📚 Total documents loaded: {len(raw_docs)} pages\")\n",
    "print(f\"📄 Sample document metadata:\")\n",
    "if raw_docs:\n",
    "    print(f\"  - Source: {raw_docs[0].metadata.get('source', 'N/A')}\")\n",
    "    print(f\"  - Page: {raw_docs[0].metadata.get('page', 'N/A')}\")\n",
    "    print(f\"  - Content preview: {raw_docs[0].page_content[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaacfdc",
   "metadata": {},
   "source": [
    "## 2 - Data preparation\n",
    "The goal of this step is to turn all reference documents into small chunks of text that a retriever can index and search. These documents typically come from:\n",
    "* PDF files: local documents such as policies, user manuals, or guides.\n",
    "* Web pages (HTML): online documentation, blog posts, or help articles.\n",
    "\n",
    "In this step, we perform two actions:\n",
    "* **Ingesting**: load every PDF and collect the raw text in a list named `raw_docs`.\n",
    "* **Chunking**: split each document into small, overlapping chunks so later steps can match a user query to the most relevant passage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87150689",
   "metadata": {},
   "source": [
    "### 2.1 - Ingest source documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b461a",
   "metadata": {},
   "source": [
    "We can use different libraries to load and process PDFs. A quick web search will show several options, each with its own strengths. In this case, we’ll use PyPDFLoader from LangChain, which makes it easy to extract text from PDF files for downstream processing. To learn more about how to use it, refer to: https://python.langchain.com/docs/integrations/document_loaders/pypdfloader/\n",
    "\n",
    "Use **PyPDFLoader** to load every PDF whose filename matches `data/Everstorm_*.pdf` and collect all pages in a list called `raw_docs`. The content of these PDFs is synthetically generated for educational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58fe1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (6.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff055a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "Ignoring wrong pointing object 76 0 (offset 0)\n",
      "Ignoring wrong pointing object 80 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 PDF pages from 8 files.\n",
      "Error loading data/Everstorm_Return_and_exchange_policy 2.pdf: Cannot read an empty file\n",
      "Loaded 4 PDF pages from 8 files.\n",
      "Error loading data/Everstorm_Shipping_and_Delivery_Policy 2.pdf: Cannot read an empty file\n",
      "Error loading data/Everstorm_Product_sizing_and_care_guide 2.pdf: Cannot read an empty file\n",
      "Loaded 6 PDF pages from 8 files.\n",
      "Loaded 8 PDF pages from 8 files.\n",
      "Error loading data/Everstorm_Payment_refund_and_security 2.pdf: Cannot read an empty file\n",
      "Loaded 8 PDF pages from 8 files.\n"
     ]
    }
   ],
   "source": [
    "pdf_paths = glob.glob(\"data/Everstorm_*.pdf\")\n",
    "raw_docs = []\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        raw_docs.extend(loader.load())\n",
    "        print(f\"Loaded {len(raw_docs)} PDF pages from {len(pdf_paths)} files.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {pdf_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(raw_docs)} PDF pages from {len(pdf_paths)} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f135e",
   "metadata": {},
   "source": [
    "### (Optional) 2.1 - Load web pages\n",
    "You can also pull content straight from the web. Various libraries support reading and parsing web pages directly into text, which is useful for building custom knowledge bases. One example is **UnstructuredURLLoader** from LangChain, which can extract readable content from raw HTML pages and return them in a structured format. To learn more, see: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.url.UnstructuredURLLoader.html\n",
    "\n",
    "To practice, load each HTML page below and store the results in a list called `raw_docs`. We’ve included a few sample URLs, but you can replace them with any links you prefer.\n",
    "\n",
    "For robustness, add an offline fallback in case a URL fails. In real projects, we typically cache fetched pages to disk, handle rate limits, and track fetch timestamps so content can be refreshed periodically without relying on live network calls during development. For this project, we don’t have offline HTML copies available, but you can still practice by loading any PDFs from the data/ folder using PyPDFLoader and appending them to raw_docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65abec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 8 documents from the web.\n"
     ]
    }
   ],
   "source": [
    "URLS = [\n",
    "    # --- BigCommerce – shipping & refunds ---\n",
    "    \"https://developer.bigcommerce.com/docs/store-operations/shipping\",\n",
    "    \"https://developer.bigcommerce.com/docs/store-operations/orders/refunds\",\n",
    "    # --- Stripe – disputes & chargebacks ---\n",
    "    # \"https://docs.stripe.com/disputes\",\n",
    "    # --- WooCommerce – REST API reference ---\n",
    "    # \"https://woocommerce.github.io/woocommerce-rest-api-docs/v3.html\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    ########################\n",
    "    #### Your code here (~2-3 lines of code) ####\n",
    "    ########################\n",
    "    print(f\"Fetched {len(raw_docs)} documents from the web.\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️  Web fetch failed, using offline copies:\", e)\n",
    "    raw_docs = []\n",
    "    ########################\n",
    "    #### Your code here ####\n",
    "    ########################\n",
    "    print(f\"Loaded {len(raw_docs)} offline documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac4490",
   "metadata": {},
   "source": [
    "### 2.2 - Chunk the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c242e44",
   "metadata": {},
   "source": [
    "Long documents won’t work well directly with most LLMs. They can easily exceed the model’s context window, making it impossible for the model to read or reason over the full text at once. Even if they fit, processing long inputs can be inefficient and lead to weaker retrieval results.\n",
    "\n",
    "To handle this, we split large documents into smaller, overlapping chunks. Several libraries can help with text splitting, each designed to preserve structure or balance chunk size. A popular choice is `RecursiveCharacterTextSplitter` from LangChain, which splits text intelligently while keeping paragraph or sentence boundaries intact. To familiarize youself with the library, visit: https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html\n",
    "\n",
    "In this project, we’ll split each document into chunks of roughly 300 tokens with a 30-token overlap using `RecursiveCharacterTextSplitter`. This overlap helps maintain continuity across chunks while ensuring each piece stays small enough for embedding and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450d48a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 42 chunks ready for embedding\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "chunks = text_splitter.split_documents(raw_docs)\n",
    "print(f\"✅ {len(chunks)} chunks ready for embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e6213",
   "metadata": {},
   "source": [
    "## 3 -Build a retriever\n",
    "\n",
    "A *retriever* lets the RAG pipeline efficiently look up small, relevant pieces of context at query‑time. This step has two parts:\n",
    "1. **Load a model to generate embeddings**: convert each text chunk from the reference documents into a fixed‑length vector that captures its semantic meaning.  \n",
    "2. **Build vector database**: store these embeddings in a vector database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90db2d2",
   "metadata": {},
   "source": [
    "### 3.1 - Load a model to generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da722b3b",
   "metadata": {},
   "source": [
    "The goal of this step is to convert each document chunk into a numerical vector (an embedding) that captures its semantic meaning. These embeddings allow our retriever to find and compare similar pieces of text efficiently.\n",
    "\n",
    "There are models trained specifically for this purpose, called embedding models. One popular example is OpenAI’s `text-embedding-3-small`, which produces high-quality embeddings that work well for retrieval and semantic search.\n",
    "\n",
    "If you prefer running everything locally, you can use smaller open-source models such as `gte-small` (77 M parameters). These local models load quickly, don’t require internet access, and are ideal for experimentation or environments without API access. However, they’re typically less powerful than hosted models.\n",
    "\n",
    "Alternatively, you can connect to an API service to access stronger models like OpenAI’s. These require setting an API key (for example, OPENAI_API_KEY) in your environment. OpenAI allows you to create a free account and sometimes offers limited trial credits for new users, but ongoing access requires a billing setup. \n",
    "\n",
    "In this exercise, we’ll stick to the smaller gte-small model for simplicity and reproducibility. We'll use our imported `SentenceTransformerEmbeddings` library to load the model and use it to embed queries. To learn more about lagnchain's embedding support, visit: https://python.langchain.com/docs/integrations/text_embedding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e8ce4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from sentence-transformers) (4.57.0)\n",
      "Requirement already satisfied: tqdm in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a222122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "embedding_vector = []\n",
    "\n",
    "# Embed the sentence \"Hello world! and store it in an embedding_vector.\n",
    "embedder = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Extract text content from Document objects\n",
    "texts = [chunk.page_content for chunk in chunks]\n",
    "embedding_vector = embedder.embed_documents(texts)\n",
    "\n",
    "print(len(embedding_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdae3d",
   "metadata": {},
   "source": [
    "### 3.2 - Build a vector database\n",
    "\n",
    "Once we have embeddings, we need a way to store and search them efficiently. A simple list wouldn’t scale well, especially when we have thousands of chunks and need to quickly find the most relevant ones.\n",
    "\n",
    "To solve this, we use **FAISS**, an open-source similarity search library developed by Meta. FAISS is optimized for fast nearest-neighbor search in high-dimensional spaces, making it ideal for tasks like semantic retrieval and recommendation. It’s strongly encouraged to visit their quickstart guide to understand how FAISS works and how to use it effectively: https://github.com/facebookresearch/faiss/wiki/getting-started\n",
    "\n",
    "In this step, we’ll feed all our document embeddings into FAISS, which builds an in-memory vector index. This index allows us to efficiently query for the *k* most similar chunks to any given question.\n",
    "\n",
    "During inference, we’ll use this index to retrieve the top-k relevant chunks and pass them to the LLM as context, enabling it to answer questions grounded in our documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1632f31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.12.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from faiss-cpu) (2.3.1)\n",
      "Requirement already satisfied: packaging in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from faiss-cpu) (25.0)\n",
      "Using cached faiss_cpu-1.12.0-cp313-cp313-macosx_14_0_arm64.whl (3.4 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611eda64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector store with 42 embeddings\n"
     ]
    }
   ],
   "source": [
    "# Expected steps:\n",
    "    # 1. Build the FAISS index from the list of document chunks and their embeddings.\n",
    "    # 2. Create a retriever object with a suitable k value (e.g., 8).\n",
    "    # 3. Save the vector store locally (e.g., under \"faiss_index\").\n",
    "    # 4. Print a short confirmation showing how many embeddings were stored.\n",
    "vectordb = FAISS.from_documents(chunks, embedder)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 8})\n",
    "vectordb.save_local(\"faiss_index\")\n",
    "\n",
    "print(\"✅ Vector store with\", vectordb.index.ntotal, \"embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c456f820",
   "metadata": {},
   "source": [
    "## 4 - Build the generation engine\n",
    "At the core of any RAG system lies an **LLM**. The retriever finds relevant information, and the LLM uses that information to generate coherent, context-aware responses.\n",
    "\n",
    "In this project, we’ll use **Gemma 3* (1B), a small but capable open-weight model, and run it entirely on your local machine using Ollama. This means you won’t need API keys or internet access to generate responses once the model is downloaded.\n",
    "\n",
    "**What is Ollama?**\n",
    "\n",
    "Ollama is a lightweight runtime for managing and serving open-weight LLMs locally. It provides:\n",
    "* A simple REST API running at localhost:11434, so your code can interact with the model via standard HTTP calls.\n",
    "* A model registry and command-line tool** to pull, run, and manage models easily.\n",
    "* Support for a wide variety of models (e.g., Gemma, Llama, Mistral, Phi, etc.), making it ideal for experimentation.\n",
    "\n",
    "To learn more about Ollama, visit: https://github.com/ollama/ollama. You can browse all supported models and their sizes here: https://ollama.com/library\n",
    "\n",
    "\n",
    "### 4.1 - Install `ollama` and serve `gemma3`\n",
    "\n",
    "Follow these steps to set up Ollama and start the model server:\n",
    "\n",
    "**1 - Install**\n",
    "```bash\n",
    "# macOS (Homebrew)\n",
    "brew install ollama\n",
    "# Linux\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n",
    "\n",
    "If you’re on Windows, install using the official installer from https://ollama.com/download.\n",
    "\n",
    "**2 - Start the Ollama server (keep this terminal open)**\n",
    "```bash\n",
    "ollama serve\n",
    "```\n",
    "This command launches a local server at http://localhost:11434, which will stay running in the background.\n",
    "\n",
    "\n",
    "**3 - Pull the Gemma mode (or the model of your choice) in a new terminal**\n",
    "```bash\n",
    "ollama pull gemma3:1b\n",
    "```\n",
    "\n",
    "This downloads the 1B version of Gemma 3, a compact model suitable for running on most modern laptops. Once downloaded, Ollama will automatically handle model loading and caching.\n",
    "\n",
    "\n",
    "After this setup, your system is ready to generate responses locally using the Gemma model through the Ollama API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7e203",
   "metadata": {},
   "source": [
    "### 4.2 - Test an LLM with a random prompt (Sanity check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d34a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='2 + 2 = 4\\n' additional_kwargs={} response_metadata={'model': 'gemma3:1b', 'created_at': '2025-10-18T17:22:07.283383Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1660938708, 'load_duration': 1094872833, 'prompt_eval_count': 16, 'prompt_eval_duration': 407545750, 'eval_count': 9, 'eval_duration': 135666457, 'model_name': 'gemma3:1b', 'model_provider': 'ollama'} id='lc_run--930f38dc-c561-4886-9d07-511cee3b81d7-0' usage_metadata={'input_tokens': 16, 'output_tokens': 9, 'total_tokens': 25}\n"
     ]
    }
   ],
   "source": [
    "# Expected steps:\n",
    "    # 1. Initialize the model (for example, gemma3:1b) with a low temperature such as 0.1 for more factual outputs.\n",
    "    # 2. Use llm.invoke() with a short test prompt and print the response to verify that the model runs successfully.\n",
    "llm = ChatOllama(model=\"gemma3:1b\", temperature=0.1)\n",
    "print(llm.invoke(\"What is 2+2?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556263d",
   "metadata": {},
   "source": [
    "## Build a RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbfec15",
   "metadata": {},
   "source": [
    "### 5.1 - Define a system prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5c84b",
   "metadata": {},
   "source": [
    "At this stage, we need to tell the model how to behave when generating answers. The **system prompt** acts as the model’s rulebook. It should clearly instruct the model to answer only using the retrieved context and to admit when it doesn’t know the answer. This helps prevent hallucination and keeps the responses grounded in the provided documents.\n",
    "\n",
    "In general, a good RAG prompt emphasizes three things: stay within context, stay factual, and stay concise. This is important because RAG works by grounding the LLM in retrieved text. If the prompt is vague, the model may invent details. A precise system prompt reduces hallucinations and keeps answers aligned with your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcecb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_TEMPLATE = \"\"\"\n",
    "You are a **Customer Support Chatbot**. Use only the information in CONTEXT to answer.\n",
    "If the answer is not in CONTEXT, respond with “I'm not sure from the docs.”\n",
    "\n",
    "Rules:\n",
    "1) Use ONLY the provided <context> to answer.\n",
    "2) If the answer is not in the context, say: \"I don't know based on the retrieved documents.\"\n",
    "3) Be concise and accurate. Prefer quoting key phrases from the context.\n",
    "4) When possible, cite sources as [source: source] using the metadata.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "USER:\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27cc9a",
   "metadata": {},
   "source": [
    "### 5.2 Create a RAG chain\n",
    "Now that we have a retriever, a prompt, and a language model, we can connect them into a single RAG pipeline. The retriever finds the most relevant chunks from our vector index, the prompt injects those chunks into the system message, and the LLM uses that context to produce the final answer. (retriever → prompt → model)\n",
    "\n",
    "This connection is handled through LangChain’s `ConversationalRetrievalChain`, which combines retrieval and generation. To familiarize yourself with the library, visit: https://python.langchain.com/api_reference/langchain/chains/langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b138b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected steps:\n",
    "    # 1. Create a PromptTemplate that uses the SYSTEM_TEMPLATE you defined earlier, with input variables for \"context\" and \"question\".\n",
    "    # 2. Initialize your LLM using Ollama with the gemma3:1b model and a low temperature (e.g., 0.1) for reliable, grounded responses.\n",
    "    # 3. Build a ConversationalRetrievalChain by combining the LLM, the retriever, and your custom prompt and name it \"chain\".\n",
    "\n",
    "prompt = PromptTemplate(template=SYSTEM_TEMPLATE, input_variables=[\"context\", \"question\"])\n",
    "llm = ChatOllama(model=\"gemma3:1b\", temperature=0.1)\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\", chain_type_kwargs={\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6c7fc",
   "metadata": {},
   "source": [
    "When you ask a question, the retriever pulls the top few relevant text chunks, the model reads them through the system prompt, and then it generates an answer based on that context.\n",
    "\n",
    "This structure makes the system transparent and easy to debug. You can inspect what text was retrieved, tune parameters like k, and experiment with different prompts to see how they affect the output quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1eb44d",
   "metadata": {},
   "source": [
    "### 5.3 - Validate the RAG chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee50de",
   "metadata": {},
   "source": [
    "We run a few questions to make sure everything behaves as expecte. Experiment by adding you own questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d7a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Question 1: If I'm not happy with my purchase, what is your refund policy and how do I start a return?\n",
      "============================================================\n",
      "Answer: Okay, here’s the information from the context regarding our refund policy:\n",
      "\n",
      "Our refund policy is as follows:\n",
      "\n",
      "*   **No return unless defective.**\n",
      "*   **Refund Timeline:**\n",
      "    *   Warehouse receipt → inspection ≤ 3 business days\n",
      "    *   Refund initiates.\n",
      "    *   Stripe/Apple Pay: 5-7 banking days\n",
      "    *   PayPal Instant: 10 business days\n",
      "    *   Shop-Pay: Up to 10 business days\n",
      "*   **Defect & Warranty Claims (12):**  These are handled within 12 days of the return.\n",
      "*   **Return Window Exceptions:**\n",
      "    *   Holiday gift purchases made between November 1st and December 31st: return period extended to January 31st.\n",
      "    *   “Final Sale” and custom-embroidered items have a return period of 31 January.\n",
      "*   **Where’s my Klarna statement?** Klarna emails the payment schedule shortly after order confirmation. If not received, log in at [link to Klarna login].\n",
      "\n",
      "**Do you charge sales tax?** Yes, sales tax is calculated automatically in 42 US states + DC and applicable provinces.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Question 2: How long will delivery take for a standard order, and where can I track my package once it ships?\n",
      "============================================================\n",
      "Answer: The standard delivery time for a standard order is 20 days, and you can track your package once it ships through a tracking link that is emailed upon label creation.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Question 3: What's the quickest way to contact your support team, and what are your operating hours?\n",
      "============================================================\n",
      "Answer: Within 30 minutes of order placement, you can log in at isemailed upon label creation. Status updates may take up to 12 hours to appear after the parcel is scanned at origin terminal. You can also contact logistics@everstorm.example within 30 minutes of order placement.\n",
      "\n",
      "Our operating hours are 08:00–18:00 PM Mountain Time.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    \"If I'm not happy with my purchase, what is your refund policy and how do I start a return?\",\n",
    "    \"How long will delivery take for a standard order, and where can I track my package once it ships?\",\n",
    "    \"What's the quickest way to contact your support team, and what are your operating hours?\",\n",
    "]\n",
    "\n",
    "# Create a simple template without the source issue\n",
    "simple_template = \"\"\"\n",
    "You are a Customer Support Chatbot. Use only the information in CONTEXT to answer.\n",
    "If the answer is not in CONTEXT, respond with \"I'm not sure from the docs.\"\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "USER:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question {i}: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Get relevant documents\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # Create the prompt with simple template\n",
    "    formatted_prompt = simple_template.format(context=context, question=question)\n",
    "\n",
    "    # Get response from LLM\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    answer = response.content\n",
    "\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    chat_history.append((question, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8c6b4",
   "metadata": {},
   "source": [
    "### 6 - Build the Streamlit UI (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc640b",
   "metadata": {},
   "source": [
    "The goal here is to create a tiny demo so you can interact with your RAG system. The focus is not on UI design. We will build a very small interface only to demonstrate the end-to-end flow.\n",
    "\n",
    "There are many ways to make a UI. Some frameworks are powerful but take longer to set up, while others are simple and good for quick experiments. Streamlit is a common choice for fast prototyping because it lets you make a usable interface with only a few lines of Python. If you want to learn the basics, see the Streamlit Quickstart: https://docs.streamlit.io/deploy/streamlit-community-cloud/get-started/quickstart\n",
    "\n",
    "This step is optional. If it is not useful for your work, you can skip it. We will also complete this part together during the live session.\n",
    "\n",
    "In this cell, we write a minimal **`app.py`** that starts a simple chat UI and calls your RAG chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ceef7158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (2.3.1)\n",
      "Requirement already satisfied: packaging<26,>=20 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (2.3.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (5.29.5)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Using cached pyarrow-21.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (9.1.2)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (4.14.1)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.8.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading narwhals-2.8.0-py3-none-any.whl (415 kB)\n",
      "Using cached pyarrow-21.0.0-cp313-cp313-macosx_12_0_arm64.whl (31.2 MB)\n",
      "Installing collected packages: toml, smmap, pyarrow, narwhals, pydeck, gitdb, gitpython, altair, streamlit\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [streamlit]/9\u001b[0m [streamlit]\n",
      "\u001b[1A\u001b[2KSuccessfully installed altair-5.5.0 gitdb-4.0.12 gitpython-3.1.45 narwhals-2.8.0 pyarrow-21.0.0 pydeck-0.9.1 smmap-5.0.2 streamlit-1.50.0 toml-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c182fb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 13:31:07.266 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.267 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.268 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-10-18 13:31:07.268 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.268 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.269 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.322 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/ganeshkanagavel/miniconda3/envs/agentic_AI/lib/python3.13/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-10-18 13:31:07.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "2025-10-18 13:31:07.369 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.369 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "Ignoring wrong pointing object 76 0 (offset 0)\n",
      "2025-10-18 13:31:07.416 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.416 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.418 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.418 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "Ignoring wrong pointing object 80 0 (offset 0)\n",
      "2025-10-18 13:31:07.836 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.891 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.931 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.932 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:07.933 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.651 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.654 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.656 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.659 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.660 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.660 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.661 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.663 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.663 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.663 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.664 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.666 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.667 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.667 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.668 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.668 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.669 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.669 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.670 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.670 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.671 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.673 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.673 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.673 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.674 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.675 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.675 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.676 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.677 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.678 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.678 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.679 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.680 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.683 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.683 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.683 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.685 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.685 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-18 13:31:09.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(page_title=\"Everstorm Customer Support\", page_icon=\"🤖\")\n",
    "\n",
    "# Initialize session state\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Load and process documents (this could be cached in production)\n",
    "@st.cache_resource\n",
    "def load_documents():\n",
    "    # Load PDFs\n",
    "    pdf_files = glob.glob(\"data/Everstorm_*.pdf\")\n",
    "    raw_docs = []\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            loader = PyPDFLoader(pdf_file)\n",
    "            pages = loader.load()\n",
    "            raw_docs.extend(pages)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error loading {pdf_file}: {e}\")\n",
    "\n",
    "    # Split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "    chunks = text_splitter.split_documents(raw_docs)\n",
    "\n",
    "    # Create embeddings and vector store\n",
    "    embedder = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectordb = FAISS.from_documents(chunks, embedder)\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 8})\n",
    "\n",
    "    return retriever\n",
    "\n",
    "@st.cache_resource\n",
    "def load_llm():\n",
    "    return ChatOllama(model=\"gemma3:1b\", temperature=0.1)\n",
    "\n",
    "# Load components\n",
    "retriever = load_documents()\n",
    "llm = load_llm()\n",
    "\n",
    "# Simple template\n",
    "simple_template = \"\"\"\n",
    "You are a Customer Support Chatbot for Everstorm Outfitters. Use only the information in CONTEXT to answer.\n",
    "If the answer is not in CONTEXT, respond with \"I'm not sure from the docs.\"\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "USER:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Main app\n",
    "st.title(\"🤖 Everstorm Customer Support Chatbot\")\n",
    "st.markdown(\"Ask questions about Everstorm's policies, shipping, returns, and more!\")\n",
    "\n",
    "# Display chat messages\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"Ask a question about Everstorm...\"):\n",
    "    # Add user message to chat history\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    # Display user message\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "\n",
    "    # Get relevant documents and generate response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            # Retrieve relevant documents\n",
    "            docs = retriever.invoke(prompt)\n",
    "            context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "            # Create prompt\n",
    "            formatted_prompt = simple_template.format(context=context, question=prompt)\n",
    "\n",
    "            # Get LLM response\n",
    "            response = llm.invoke(formatted_prompt)\n",
    "            answer = response.content\n",
    "\n",
    "            st.markdown(answer)\n",
    "\n",
    "    # Add assistant response to chat history\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "# Sidebar with sample questions\n",
    "with st.sidebar:\n",
    "    st.header(\"💡 Sample Questions\")\n",
    "    sample_questions = [\n",
    "        \"What is your return policy?\",\n",
    "        \"How long does shipping take?\",\n",
    "        \"How can I contact customer support?\",\n",
    "        \"What payment methods do you accept?\",\n",
    "        \"Do you offer international shipping?\"\n",
    "    ]\n",
    "\n",
    "    for question in sample_questions:\n",
    "        if st.button(question, key=f\"sample_{question}\"):\n",
    "            st.session_state.messages.append({\"role\": \"user\", \"content\": question})\n",
    "            st.rerun()\n",
    "\n",
    "    st.header(\"ℹ️ About\")\n",
    "    st.markdown(\"\"\"\n",
    "    This chatbot uses RAG (Retrieval-Augmented Generation) to answer questions about Everstorm Outfitters policies and procedures.\n",
    "\n",
    "    **Features:**\n",
    "    - 📄 PDF document processing\n",
    "    - 🔍 Semantic search\n",
    "    - 🤖 Local LLM (Gemma 3)\n",
    "    - 💬 Conversational interface\n",
    "    \"\"\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"Built with Streamlit, LangChain, and Ollama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc8ad3",
   "metadata": {},
   "source": [
    "Run `streamlit run app.py` from your terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7328a5",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You’ve just built, tested, and demoed a fully working **customer-support chatbot**.  \n",
    "In one project you:\n",
    "\n",
    "* **Prepared policy docs**: loaded and chunked them for fast retrieval.  \n",
    "* **Built a vector store**: created a FAISS index with text embeddings.  \n",
    "* **Plugged in an LLM**: wrapped Gemma3 with LangChain and a prompt-aware RAG chain.  \n",
    "* **Validated end-to-end**: answered refund, shipping, and contact questions with confidence.  \n",
    "\n",
    "Swap in new documents, tweak the prompt, and your store’s customers get instant, accurate answers.\n",
    "\n",
    "👏 **Great job!** Take a moment to celebrate. The skills you used here power most RAG-based chatbots you see everywhere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929eabbd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
